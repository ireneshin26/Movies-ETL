# Movies-ETL
Overview: Purpose was to create an automated pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables by refactoring the code from the module to create one function that takes in the three files—Wikipedia data, Kaggle metadata, and the MovieLens rating data—and performs the ETL process by adding the data to a PostgreSQL database.

# Resources
* Wikipedia Movie Data: wikipedia-movies.json
* Kaggle Data: ratings.csv and movies_metadata.csv

# Tools
* pgAdmin4 Version 6.12 (4280.88)
* PostGreSQL version 14
* Python version 3.9.12 
* Jupyter Notebook version 6.4.8Matplotlib version 3.5.1

# Results
## Deliverable 1: [Write an ETL function to read three data files](https://github.com/ireneshin26/Movies-ETL/blob/main/Deliverable1-ETL_function_test.ipynb)
## Deliverable 2: [Extract and Transform the Wikipedia Data](https://github.com/ireneshin26/Movies-ETL/blob/main/Deliverable2-ETL_clean_wiki_movies.ipynb)
## Deliverable 3: [Extract and Transform the Kaggle Data](https://github.com/ireneshin26/Movies-ETL/blob/main/Deliverable3-ETL_clean_kaggle_data.ipynb)
## Deliverable 4: [Create the Movie Database](https://github.com/ireneshin26/Movies-ETL/blob/main/Deliverable4-ETL_create_database.ipynb)
* [Movies_Query.png](https://github.com/ireneshin26/Movies-ETL/blob/main/movies_query.png)
* [Ratings_Query.png](https://github.com/ireneshin26/Movies-ETL/blob/main/ratings_query.png)

